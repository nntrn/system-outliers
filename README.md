# System Outliers

> "*There is no science without fancy and no art without fact.*" ---
> Vladimir Nabokov

## About

*too structural for ML, too symbolic for physics, too dynamic for
logic, and too interpretive for engineering*

This is a structural classification framework for deviant signals. It
distinguishes between reactive, structural, hybrid, and residual
outliers based on their symbolic behavior, recursion tolerance, and
system-relative context. This framework resists premature
classification, protects structural ambiguity, and identifies failure
modes in outlier reasoning, including symbolic displacement feedback.

It extends concepts from:

- Opinion dynamics (H-K)
- Compression logic (Shannon)
- Recursive identity systems (Peirce, control theory)
- Grammar as behavior (structural linguistics)

## Usage

Drop [system-outliers-annie.txt](system-outliers-annie.txt) into
ChatGPT to explore framework.

<p align="center"><a href="system-outliers-annie.txt">
<img width="70%" src="docs/usage-chatgpt.png" /></a></p>

### Use ChatGPT to explore how the framework works.

GPT is faster with the framework because it externalizes deviance
logic into structured classification mechanics by providing:

- A compressed decision surface (rules over heuristics),
- A recursion-visible signal trace,
- A bias-free deviance vector space.

This removes semantic negotiation, rhetorical padding, and output
validation. Speed increases because structure replaces guesswork.

## Framework

- **Entropy vs. Magnitude**
  - Entropy = divergent futures
  - Magnitude = energy displacement
- **Reactive vs. Systematic**
  - Reactive = volatility, collapse under iteration
  - Systematic = stable under symbolic recursion, model-incomplete not
    model-breaking
- **Grammatical Typing (Noun / Verb / Adjective)**
  - Noun = static deviance (identity)
  - Verb = structural pressure (disruptive force)
  - Adjective = apparent normalcy, deep misalignment (compression
    mismatch)
- **Temporal Role**
  - Some outliers reshape the current system
  - Others only reshape future trajectories (entropy-dominant)
- **Working Principles**
  - Don't filter what you haven't compressed
  - Structural deviants are not rare—they're misclassified
  - Removing deviance reshapes the model boundary, not just the
    dataset
  - Big players aren't edge cases—they're constraint points


## Purpose

To provide a classification grammar that distinguishes between types
of deviance based on recursive behavior, symbolic trace, and
entropy/magnitude pressure—enabling systems (human or machine) to
preserve structural outliers and correctly discard reactive ones.

**Framework Goal:** Deliver a principled way to classify anomalies by
structure, traceability, and compressibility, not just statistical
deviation.

<!-- 
### Getting Started
1. **Is this outlier structurally consistent or behaviorally disruptive?**  
    Answer using: Structural = trace_like=1; Reactive = trace_like=0
2. **Does this deviance result from system pressure or rupture?**  
    Answer using: Hybrid vs Reactive differentiation
3. **Should this anomaly be discarded, flagged, or tracked?**  
    Answer using: Residual classification logic
4. **Is the system recursively generating without symbolic yield?**  
    Answer using: Use symbolic displacement feedback (SDF)
5. **Does this signal preserve, stress, or shift the system?**  
    Answer using: Noun/Verb/Adjective symbolic role analysis
6. **Is this behavior a compression failure or a boundary escape?**  
    Answer using: Entropy/magnitude separation + recursion fidelity monitoring 
-->

## Acknowledgment

This framework was shaped in part by the tone and structure of *A
General Theory of Love (Lewis, 2000)*, it models a rare epistemic
balance by honoring scientific structure without reducing human
systems and introducing symbolic coherence without overwriting
emotional complexity.

Developed collaboratively through recursive interaction with ChatGPT.

## License

[LICENSE.txt](LICENSE.txt)
